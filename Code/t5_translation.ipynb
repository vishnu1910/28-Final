{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-08T15:03:01.996149Z","iopub.status.busy":"2024-05-08T15:03:01.995733Z","iopub.status.idle":"2024-05-08T15:03:14.329264Z","shell.execute_reply":"2024-05-08T15:03:14.328407Z","shell.execute_reply.started":"2024-05-08T15:03:01.996114Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f72931e261aa4bcf9d709338157b4807","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3237f2ff40c34fc2b31c8020147e581e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b4a3019f37442b5baf9aa07f421adfb","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2888df8fb1334c68a3d0b09a388e88cc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94b1252074e347aba6ffb9794648385d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c532ef766cf2490d9f7149b746b4a35f","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","from transformers import default_data_collator\n","from transformers import HfArgumentParser\n","import pandas as pd\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_name = \"t5-small\"\n","config = AutoConfig.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=config).to(device)\n","\n","# dataset = load_dataset('findnitai/english-to-hinglish')\n","# master = [line['en'] for line in dataset['train']['translation']]\n","# master += [line['hi_ng'] for line in dataset['train']['translation']]\n","\n","df = pd.read_csv(\"/kaggle/input/engtohing/train_new.txt\", sep='\\t', header=None, names=['eng', 'hing'])\n","master = df['eng'].tolist()\n","master+= df['hing'].tolist()\n","\n","# dataset.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:03:14.331452Z","iopub.status.busy":"2024-05-08T15:03:14.330997Z","iopub.status.idle":"2024-05-08T15:03:14.338322Z","shell.execute_reply":"2024-05-08T15:03:14.337287Z","shell.execute_reply.started":"2024-05-08T15:03:14.331420Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["T5Config {\n","  \"_name_or_path\": \"t5-small\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"classifier_dropout\": 0.0,\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"relu\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": false,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 6,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.39.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n"]}],"source":["print(config)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:03:14.339860Z","iopub.status.busy":"2024-05-08T15:03:14.339546Z","iopub.status.idle":"2024-05-08T15:03:14.347848Z","shell.execute_reply":"2024-05-08T15:03:14.346905Z","shell.execute_reply.started":"2024-05-08T15:03:14.339808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["248330\n"]}],"source":["print(len(df))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:03:14.350239Z","iopub.status.busy":"2024-05-08T15:03:14.349894Z","iopub.status.idle":"2024-05-08T15:03:29.516452Z","shell.execute_reply":"2024-05-08T15:03:29.515471Z","shell.execute_reply.started":"2024-05-08T15:03:14.350216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['translation'],\n","    num_rows: 248330\n","})\n"]}],"source":["from datasets import Dataset\n","data = []\n","for index, row in df.iterrows():\n","    data.append({\n","        'en': row['eng'],\n","        'hi_ng': row['hing']\n","    })\n","\n","# Create a Dataset object\n","dataset = Dataset.from_dict({'translation': data})\n","\n","print(dataset)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:03:29.518007Z","iopub.status.busy":"2024-05-08T15:03:29.517682Z","iopub.status.idle":"2024-05-08T15:03:29.527866Z","shell.execute_reply":"2024-05-08T15:03:29.526792Z","shell.execute_reply.started":"2024-05-08T15:03:29.517980Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'translation': {'en': 'Hindi Milaap From Hyderbad', 'hi_ng': 'Hindi Milaap From Hyderbad'}}\n"]}],"source":["print(dataset[0])"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-08T15:03:29.529389Z","iopub.status.busy":"2024-05-08T15:03:29.529113Z","iopub.status.idle":"2024-05-08T15:03:51.519232Z","shell.execute_reply":"2024-05-08T15:03:51.517754Z","shell.execute_reply.started":"2024-05-08T15:03:29.529365Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (master[i : i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m500\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(master), \u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m      4\u001b[0m tokenizer_training_data \u001b[38;5;241m=\u001b[39m gen_training_data()\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_new_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_training_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(source_data):\n\u001b[1;32m      8\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m source_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:791\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.train_new_from_iterator\u001b[0;34m(self, text_iterator, vocab_size, length, new_special_tokens, special_tokens_map, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m trainer_class \u001b[38;5;241m=\u001b[39m MODEL_TO_TRAINER_MAPPING[tokenizer_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    790\u001b[0m trainer \u001b[38;5;241m=\u001b[39m trainer_class(vocab_size\u001b[38;5;241m=\u001b[39mvocab_size, special_tokens\u001b[38;5;241m=\u001b[39mspecial_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 791\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m     trained_tokenizer_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tokenizer\u001b[38;5;241m.\u001b[39mto_str())\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def gen_training_data():\n","    return (master[i : i+500] for i in range(0, len(master), 500))\n","\n","tokenizer_training_data = gen_training_data()\n","tokenizer = tokenizer.train_new_from_iterator(tokenizer_training_data, 32128)\n","\n","def preprocess(source_data):\n","    inputs = [sample['en'] for sample in source_data[\"translation\"]]\n","    targets = [sample['hi_ng'] for sample in source_data[\"translation\"]]\n","    inputs = [\"Translate English to Hinglish: \" + inp for inp in inputs]\n","    model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n","    labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n","    labels[\"input_ids\"] = [[l if l != tokenizer.pad_token_id else -100 for l in label] for label in labels[\"input_ids\"]]\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","raw_dataset = {\"train\": dataset}\n","train_dataset = raw_dataset[\"train\"].map(preprocess, batched=True, remove_columns=\"translation\")\n","print(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:03:51.520448Z","iopub.status.idle":"2024-05-08T15:03:51.520799Z","shell.execute_reply":"2024-05-08T15:03:51.520645Z","shell.execute_reply.started":"2024-05-08T15:03:51.520631Z"},"trusted":true},"outputs":[],"source":["print(raw_dataset['train']['translation'][:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-08T15:03:51.521961Z","iopub.status.idle":"2024-05-08T15:03:51.522271Z","shell.execute_reply":"2024-05-08T15:03:51.522131Z","shell.execute_reply.started":"2024-05-08T15:03:51.522118Z"},"trusted":true},"outputs":[],"source":["data_collator = default_data_collator\n","\n","num_epochs = 3\n","trainer_args_in = {\n","    'output_dir': 'my-t5-hinglish-translator',\n","    'overwrite_output_dir': True,\n","    'do_train': True,\n","    'per_device_train_batch_size': 8,\n","    'num_train_epochs': num_epochs,\n","    'save_strategy': 'no',\n","    'report_to' : []\n","}\n","\n","parser = HfArgumentParser((Seq2SeqTrainingArguments,))\n","training_args = parser.parse_dict(trainer_args_in)\n","trainer = Seq2SeqTrainer(model=model, args=training_args[0], train_dataset=train_dataset, tokenizer=tokenizer, data_collator=data_collator)\n","\n","train_result = trainer.train(resume_from_checkpoint=None)\n","trainer.save_model()\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"my-t5-hinglish-translator\").to(device)\n","input_text = \"translate English to Hinglish: How is the weather?\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","outputs = model.generate(input_ids)\n","print(\"Test Output: \" + tokenizer.decode(outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:06:16.611227Z","iopub.status.idle":"2024-05-07T13:06:16.611675Z","shell.execute_reply":"2024-05-07T13:06:16.611467Z","shell.execute_reply.started":"2024-05-07T13:06:16.611449Z"},"trusted":true},"outputs":[],"source":["# import torch\n","# from datasets import load_dataset, Dataset\n","# from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","# from transformers import default_data_collator\n","# import pandas as pd\n","# from transformers import HfArgumentParser\n","\n","# # Check if GPU is available\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Model configuration\n","# model_name = \"t5-small\"\n","# config = AutoConfig.from_pretrained(model_name)\n","# tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","# model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=config).to(device)\n","\n","# df = pd.read_csv(\"/kaggle/input/engtohing/train_new.txt\", sep='\\t', header=None, names=['eng', 'hing'])\n","# master = df['eng'].tolist()\n","# master+= df['hing'].tolist()\n","\n","# data = []\n","# for index, row in df.iterrows():\n","#     data.append({\n","#         'en': row['eng'],\n","#         'hi_ng': row['hing']\n","#     })\n","\n","# # Create a Dataset object\n","# dataset = Dataset.from_dict({'translation': data})\n","\n","# # Tokenizer training data\n","# def gen_training_data():\n","#     return (master[i : i+500] for i in range(0, len(master), 500))\n","\n","# tokenizer_training_data = gen_training_data()\n","# tokenizer = tokenizer.train_new_from_iterator(tokenizer_training_data, 32128)\n","\n","# # Data preprocessing\n","# def preprocess(source_data):\n","#     inputs = [sample['en'] for sample in source_data[\"translation\"]]\n","#     targets = [sample['hi_ng'] for sample in source_data[\"translation\"]]\n","#     inputs = [\"Translate English to Hinglish: \" + inp for inp in inputs]\n","#     model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n","#     labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n","#     labels[\"input_ids\"] = [[l if l != tokenizer.pad_token_id else -100 for l in label] for label in labels[\"input_ids\"]]\n","#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n","#     return model_inputs\n","\n","# raw_dataset = {\"train\": dataset}\n","# train_dataset = raw_dataset[\"train\"].map(preprocess, batched=True, remove_columns=\"translation\")\n","# data_collator = default_data_collator\n","\n","# # # Training arguments\n","# # num_epochs = 3\n","# # training_args = Seq2SeqTrainingArguments(\n","# #     output_dir='my-t5-hinglish-translator',\n","# #     overwrite_output_dir=True,\n","# #     do_train=True,\n","# #     per_device_train_batch_size=8,\n","# #     num_train_epochs=num_epochs,\n","# #     'save_strategy': 'no'\n","# # )\n","\n","# num_epochs = 2\n","# trainer_args_in = {\n","#     'output_dir': 'my-t5-hinglish-translator',\n","#     'overwrite_output_dir': True,\n","#     'do_train': True,\n","#     'per_device_train_batch_size': 8,\n","#     'num_train_epochs': num_epochs,\n","#     'save_strategy': 'no'\n","# }\n","\n","# parser = HfArgumentParser((Seq2SeqTrainingArguments,))\n","# training_args = parser.parse_dict(trainer_args_in)\n","# # trainer = Seq2SeqTrainer(model=model, args=training_args[0], train_dataset=train_dataset, tokenizer=tokenizer, data_collator=data_collator)\n","\n","\n","# # Load checkpoint if available\n","# checkpoint_path = '/kaggle/input/t5-3epoch/kaggle/working/my-t5-hinglish-translator'  # Update with your checkpoint folder path\n","# if checkpoint_path:\n","#     trainer = Seq2SeqTrainer(\n","#         model=model,\n","#         args=training_args[0],\n","#         train_dataset=train_dataset,\n","#         tokenizer=tokenizer,\n","#         data_collator=data_collator\n","#     )\n","# else:\n","#     trainer = Seq2SeqTrainer(\n","#         model=model,\n","#         args=training_args,\n","#         train_dataset=train_dataset,\n","#         tokenizer=tokenizer,\n","#         data_collator=data_collator\n","#     )\n","\n","# # Continue training\n","# trainer.train(resume_from_checkpoint=checkpoint_path)\n","# trainer.save_model()\n","\n","# # Inference\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"my-t5-hinglish-translator\").to(device)\n","# input_text = \"translate English to Hinglish: How is the weather?\"\n","# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","# outputs = model.generate(input_ids)\n","# print(\"Test Output: \" + tokenizer.decode(outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:43:44.672403Z","iopub.status.busy":"2024-05-08T15:43:44.672042Z","iopub.status.idle":"2024-05-08T15:43:45.178909Z","shell.execute_reply":"2024-05-08T15:43:45.178082Z","shell.execute_reply.started":"2024-05-08T15:43:44.672376Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Load tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/t5-3epoch/kaggle/working/my-t5-hinglish-translator\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/t5-3epoch/kaggle/working/my-t5-hinglish-translator\").to(device)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:46:21.076119Z","iopub.status.busy":"2024-05-08T15:46:21.075389Z","iopub.status.idle":"2024-05-08T15:46:21.183083Z","shell.execute_reply":"2024-05-08T15:46:21.182130Z","shell.execute_reply.started":"2024-05-08T15:46:21.076085Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: translate english to hinglish: This fact is based on possibility\n","Output: यह fact possibility पर based है ।\n"]}],"source":["# Generate output\n","input_text = \"translate english to hinglish: This fact is based on possibility\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","outputs = model.generate(input_ids)\n","output_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(\"Input:\", input_text)\n","print(\"Output:\", output_string)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:43:48.728077Z","iopub.status.busy":"2024-05-08T15:43:48.727469Z","iopub.status.idle":"2024-05-08T15:43:49.744310Z","shell.execute_reply":"2024-05-08T15:43:49.743207Z","shell.execute_reply.started":"2024-05-08T15:43:48.728045Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/my-t5-hinglish-translator/ (stored 0%)\n","  adding: kaggle/working/my-t5-hinglish-translator/runs/ (stored 0%)\n","  adding: kaggle/working/my-t5-hinglish-translator/runs/May07_15-25-02_b42c6a7ce932/ (stored 0%)\n","  adding: kaggle/working/my-t5-hinglish-translator/runs/May07_15-25-02_b42c6a7ce932/events.out.tfevents.1715095503.b42c6a7ce932.34.0 (deflated 69%)\n"]},{"data":{"text/html":["<a href='my-t5-hinglish-translator.zip' target='_blank'>my-t5-hinglish-translator.zip</a><br>"],"text/plain":["/kaggle/working/my-t5-hinglish-translator.zip"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","!zip -r my-t5-hinglish-translator /kaggle/working/my-t5-hinglish-translator\n","from IPython.display import FileLink\n","FileLink(r'my-t5-hinglish-translator.zip')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:47:49.185584Z","iopub.status.busy":"2024-05-08T15:47:49.184778Z","iopub.status.idle":"2024-05-08T15:47:49.206095Z","shell.execute_reply":"2024-05-08T15:47:49.205179Z","shell.execute_reply.started":"2024-05-08T15:47:49.185548Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","def translate_text_pytorch(text, model, tokenizer):\n","    input_text = \"translate english to hinglish: \" + text\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","    outputs = model.generate(input_ids)\n","    output_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return output_string\n","\n","\n","df_test = pd.read_csv('/kaggle/input/engtohing/test_new.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","en_test = df_test['en']\n","hing_test = df_test['hing']\n","texts = list(en_test)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:47:25.343324Z","iopub.status.busy":"2024-05-08T15:47:25.342919Z","iopub.status.idle":"2024-05-08T15:47:25.468626Z","shell.execute_reply":"2024-05-08T15:47:25.467732Z","shell.execute_reply.started":"2024-05-08T15:47:25.343295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["translate english to hinglish: This fact is based on possibility यह fact possibility पर based है ।\n"]}],"source":["input_text = \"translate english to hinglish: \"+texts[0]\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","outputs = model.generate(input_ids)\n","output_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(input_text ,output_string)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:47:51.826711Z","iopub.status.busy":"2024-05-08T15:47:51.825869Z","iopub.status.idle":"2024-05-08T15:51:04.874264Z","shell.execute_reply":"2024-05-08T15:51:04.873218Z","shell.execute_reply.started":"2024-05-08T15:47:51.826677Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","100%|██████████| 2000/2000 [03:13<00:00, 10.36it/s]\n"]}],"source":["\n","translated = []\n","for text in tqdm(texts):\n","    translated.append(translate_text_pytorch(text, model, tokenizer))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:51:09.952388Z","iopub.status.busy":"2024-05-08T15:51:09.951779Z","iopub.status.idle":"2024-05-08T15:51:09.959163Z","shell.execute_reply":"2024-05-08T15:51:09.958197Z","shell.execute_reply.started":"2024-05-08T15:51:09.952355Z"},"trusted":true},"outputs":[],"source":["with open('translated.txt', 'w', encoding='utf-8') as file:\n","    for translate in translated:\n","        file.write(translate + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4958257,"sourceId":8346529,"sourceType":"datasetVersion"},{"datasetId":4952829,"sourceId":8354411,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
