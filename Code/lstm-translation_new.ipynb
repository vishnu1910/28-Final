{"cells":[{"cell_type":"markdown","metadata":{},"source":["# English to Hinglish Generation\n","\n","Here we are trying to generate Hinglish sentence by English sentence "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:25:42.454527Z","iopub.status.busy":"2024-05-08T05:25:42.453651Z","iopub.status.idle":"2024-05-08T05:25:44.130864Z","shell.execute_reply":"2024-05-08T05:25:44.130096Z","shell.execute_reply.started":"2024-05-08T05:25:42.454490Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# dfd = pd.read_csv('/kaggle/input/hinglish-dataset/dev.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","# print(dfd.shape)\n","# dfd = dfd.sample(frac=1, random_state=42)\n","# dfd = dfd.reset_index(drop=True)\n","# dfd.head()\n","\n","\n","df = pd.read_csv('/kaggle/input/enhingdataset/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:27:39.103897Z","iopub.status.busy":"2024-05-08T05:27:39.103546Z","iopub.status.idle":"2024-05-08T05:27:39.108374Z","shell.execute_reply":"2024-05-08T05:27:39.107430Z","shell.execute_reply.started":"2024-05-08T05:27:39.103867Z"},"trusted":true},"outputs":[],"source":["# df1 = pd.read_csv(\"/kaggle/input/hinglish-dataset/ManualAnalysis.csv\")\n","# df1 = df1[[\"src\", \"tgt\"]]\n","# df1 = df1.rename(columns = {\"src\":\"en\", \"tgt\":\"hing\"})\n","# df = pd.read_csv('/kaggle/input/hinglish-dataset/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","# df = df.sample(frac=1, random_state=42)\n","# df = df.reset_index(drop=True)\n","# df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:27:39.933340Z","iopub.status.busy":"2024-05-08T05:27:39.933022Z","iopub.status.idle":"2024-05-08T05:27:39.954615Z","shell.execute_reply":"2024-05-08T05:27:39.953691Z","shell.execute_reply.started":"2024-05-08T05:27:39.933316Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>hing</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hindi Milaap From Hyderbad</td>\n","      <td>Hindi Milaap From Hyderbad</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Pension Fund Managers PFMs</td>\n","      <td>Pension Fund PFMs</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A new roll of blotting paper has been ordered</td>\n","      <td>blotting paper के new roll का आदेश दिया गया है ।</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Accelerated Irrigation Benefits Programme</td>\n","      <td>त्वरित Irrigation Benefits Programme</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>So they go deep inside mines</td>\n","      <td>इस लिए वह भूमि के अन्दर गहरे mines है</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>248325</th>\n","      <td>Color packages by their status</td>\n","      <td>packages उनकी स्थिती के अनुसार रंगें</td>\n","    </tr>\n","    <tr>\n","      <th>248326</th>\n","      <td>Disable screensaver when playing</td>\n","      <td>screensaver निष्क्रिय करें</td>\n","    </tr>\n","    <tr>\n","      <th>248327</th>\n","      <td>Default list of columns visible in the list view</td>\n","      <td>list दृश्य में दृष्टिगोचर columns की Default list</td>\n","    </tr>\n","    <tr>\n","      <th>248328</th>\n","      <td>K3b Video DVD Restrictions</td>\n","      <td>K3b Video DVD Restrictions</td>\n","    </tr>\n","    <tr>\n","      <th>248329</th>\n","      <td>Semi urban Areas Rs 10 00 000</td>\n","      <td>Semi क्षेत्र में Rs 1000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>248330 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                      en  \\\n","0                             Hindi Milaap From Hyderbad   \n","1                             Pension Fund Managers PFMs   \n","2          A new roll of blotting paper has been ordered   \n","3              Accelerated Irrigation Benefits Programme   \n","4                           So they go deep inside mines   \n","...                                                  ...   \n","248325                    Color packages by their status   \n","248326                  Disable screensaver when playing   \n","248327  Default list of columns visible in the list view   \n","248328                        K3b Video DVD Restrictions   \n","248329                     Semi urban Areas Rs 10 00 000   \n","\n","                                                     hing  \n","0                              Hindi Milaap From Hyderbad  \n","1                                       Pension Fund PFMs  \n","2        blotting paper के new roll का आदेश दिया गया है ।  \n","3                    त्वरित Irrigation Benefits Programme  \n","4                   इस लिए वह भूमि के अन्दर गहरे mines है  \n","...                                                   ...  \n","248325               packages उनकी स्थिती के अनुसार रंगें  \n","248326                         screensaver निष्क्रिय करें  \n","248327  list दृश्य में दृष्टिगोचर columns की Default list  \n","248328                         K3b Video DVD Restrictions  \n","248329                        Semi क्षेत्र में Rs 1000000  \n","\n","[248330 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:27:43.168457Z","iopub.status.busy":"2024-05-08T05:27:43.168112Z","iopub.status.idle":"2024-05-08T05:27:45.257432Z","shell.execute_reply":"2024-05-08T05:27:45.256549Z","shell.execute_reply.started":"2024-05-08T05:27:43.168431Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>hing</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hindi Milaap From Hyderbad</td>\n","      <td>[start] Hindi Milaap From Hyderbad [end]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Pension Fund Managers PFMs</td>\n","      <td>[start] Pension Fund PFMs [end]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A new roll of blotting paper has been ordered</td>\n","      <td>[start] blotting paper के new roll का आदेश दिय...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Accelerated Irrigation Benefits Programme</td>\n","      <td>[start] त्वरित Irrigation Benefits Programme [...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>So they go deep inside mines</td>\n","      <td>[start] इस लिए वह भूमि के अन्दर गहरे mines है ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>248325</th>\n","      <td>Color packages by their status</td>\n","      <td>[start] packages उनकी स्थिती के अनुसार रंगें [...</td>\n","    </tr>\n","    <tr>\n","      <th>248326</th>\n","      <td>Disable screensaver when playing</td>\n","      <td>[start] screensaver निष्क्रिय करें [end]</td>\n","    </tr>\n","    <tr>\n","      <th>248327</th>\n","      <td>Default list of columns visible in the list view</td>\n","      <td>[start] list दृश्य में दृष्टिगोचर columns की D...</td>\n","    </tr>\n","    <tr>\n","      <th>248328</th>\n","      <td>Kb Video DVD Restrictions</td>\n","      <td>[start] Kb Video DVD Restrictions [end]</td>\n","    </tr>\n","    <tr>\n","      <th>248329</th>\n","      <td>Semi urban Areas Rs</td>\n","      <td>[start] Semi क्षेत्र में Rs  [end]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>248330 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                      en  \\\n","0                             Hindi Milaap From Hyderbad   \n","1                             Pension Fund Managers PFMs   \n","2          A new roll of blotting paper has been ordered   \n","3              Accelerated Irrigation Benefits Programme   \n","4                           So they go deep inside mines   \n","...                                                  ...   \n","248325                    Color packages by their status   \n","248326                  Disable screensaver when playing   \n","248327  Default list of columns visible in the list view   \n","248328                         Kb Video DVD Restrictions   \n","248329                            Semi urban Areas Rs      \n","\n","                                                     hing  \n","0                [start] Hindi Milaap From Hyderbad [end]  \n","1                         [start] Pension Fund PFMs [end]  \n","2       [start] blotting paper के new roll का आदेश दिय...  \n","3       [start] त्वरित Irrigation Benefits Programme [...  \n","4       [start] इस लिए वह भूमि के अन्दर गहरे mines है ...  \n","...                                                   ...  \n","248325  [start] packages उनकी स्थिती के अनुसार रंगें [...  \n","248326           [start] screensaver निष्क्रिय करें [end]  \n","248327  [start] list दृश्य में दृष्टिगोचर columns की D...  \n","248328            [start] Kb Video DVD Restrictions [end]  \n","248329                 [start] Semi क्षेत्र में Rs  [end]  \n","\n","[248330 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# import re\n","# from unicodedata import normalize\n","\n","# def clean_text(text):\n","#     text = text.lower()\n","#     text = normalize('NFD', text)\n","#     cleaned_text = ''\n","#     for char in text:\n","#         if char.isalpha() or char == ' ':\n","#             cleaned_text += char\n","#     return cleaned_text\n","\n","# df['en'] = df['en'].apply(lambda row: clean_text(row))\n","# df['hing'] = df['hing'].apply(lambda row: clean_text(row))\n","# df.head()\n","\n","import numpy as np\n","import re\n","from unicodedata import normalize\n","\n","\n","def clean_text(text, language='en'):\n","    if isinstance(text, float) and np.isnan(text):  # Check if text is NaN\n","        return ''  # Return empty string for NaN values\n","    text = normalize('NFD', text)\n","    if language == 'en':\n","        text = re.sub('[^A-Za-z .\\']+', '', text)\n","    elif language == 'hing': \n","        text = re.sub('[^\\u0900-\\u097F A-Za-z .\\']+', '', text)\n","    return text\n","\n","def clean_and_prepare_text(text, language='hing'):\n","    text = '[start] ' + clean_text(text, language=language) + ' [end]'\n","    return text\n","\n","# Apply it to your dataframe like this:\n","\n","\n","df['en'] = df['en'].apply(lambda row: clean_text(row, language='en'))\n","df['hing'] = df['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\n","df\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:27:46.513651Z","iopub.status.busy":"2024-05-08T05:27:46.513292Z","iopub.status.idle":"2024-05-08T05:27:46.951094Z","shell.execute_reply":"2024-05-08T05:27:46.950195Z","shell.execute_reply.started":"2024-05-08T05:27:46.513623Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Max phrase length (English): 10\n","Max phrase length (Hinglish): 114\n"]}],"source":["en = df['en']\n","hing = df['hing']\n","\n","en_max_len = max(len(line.split()) for line in en)\n","hing_max_len = max(len(line.split()) for line in hing)\n","\n","print(f'Max phrase length (English): {en_max_len}')\n","print(f'Max phrase length (Hinglish): {hing_max_len}')\n","\n","sequence_len = max(en_max_len,hing_max_len)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:27:50.243739Z","iopub.status.busy":"2024-05-08T05:27:50.242882Z","iopub.status.idle":"2024-05-08T05:28:05.405617Z","shell.execute_reply":"2024-05-08T05:28:05.404800Z","shell.execute_reply.started":"2024-05-08T05:27:50.243706Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","import torch\n","class Tokenizer:\n","    def __init__(self):\n","        self.word_index = {}\n","        self.index_word = {}\n","    \n","    def fit_on_texts(self, texts):\n","        word_freq = defaultdict(int)\n","        for text in texts:\n","            for word in text.split():\n","                word_freq[word] += 1\n","        self.word_index = {word: i+1 for i, (word, freq) in enumerate(sorted(word_freq.items(), key=lambda x: x[1], reverse=True))}\n","        self.index_word = {i: word for word, i in self.word_index.items()}\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            seq = [self.word_index.get(word, 0) for word in text.split()]\n","            sequences.append(seq)\n","        return sequences\n","    \n","    def sequences_to_texts(self, sequences):\n","        texts = []\n","        for sequence in sequences:\n","            words = [self.index_word.get(idx, \"<unk>\") for idx in sequence if idx > 0]  # Skip padding\n","            text = \" \".join(words)\n","            texts.append(text)\n","        return texts\n","\n","def pad_sequences(sequences, maxlen, padding='post'):\n","    max_seq_len = max(len(seq) for seq in sequences)\n","    padded_seqs = torch.zeros((len(sequences), maxlen), dtype=torch.long)\n","    for i, seq in enumerate(sequences):\n","        if padding == 'post':\n","            padded_seqs[i, :len(seq)] = torch.tensor(seq[:maxlen], dtype=torch.long)\n","        else:  \n","            padded_seqs[i, -len(seq):] = torch.tensor(seq[-maxlen:], dtype=torch.long)\n","    return padded_seqs\n","\n","en_tokenizer = Tokenizer()\n","en_tokenizer.fit_on_texts(en)\n","en_sequences = en_tokenizer.texts_to_sequences(en)\n","en_x = pad_sequences(en_sequences, maxlen=en_max_len, padding='post')\n","\n","hing_tokenizer = Tokenizer()\n","hing_tokenizer.fit_on_texts(hing)\n","hing_sequences = hing_tokenizer.texts_to_sequences(hing)\n","hing_y = pad_sequences(hing_sequences, maxlen=hing_max_len, padding='post')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:28:05.407455Z","iopub.status.busy":"2024-05-08T05:28:05.407076Z","iopub.status.idle":"2024-05-08T05:28:05.412889Z","shell.execute_reply":"2024-05-08T05:28:05.412025Z","shell.execute_reply.started":"2024-05-08T05:28:05.407431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary size (English): 81406\n","Vocabulary size (Hinglish): 114113\n"]}],"source":["en_vocab_size = len(en_tokenizer.word_index) + 1\n","hing_vocab_size = len(hing_tokenizer.word_index) + 1\n","\n","print(f'Vocabulary size (English): {en_vocab_size}')\n","print(f'Vocabulary size (Hinglish): {hing_vocab_size}')"]},{"cell_type":"markdown","metadata":{},"source":["## Train a model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:43:48.094105Z","iopub.status.busy":"2024-05-08T05:43:48.093108Z","iopub.status.idle":"2024-05-08T05:43:51.375783Z","shell.execute_reply":"2024-05-08T05:43:51.374818Z","shell.execute_reply.started":"2024-05-08T05:43:48.094068Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/4092959309.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  en_x = torch.tensor(en_x, dtype=torch.long).to(device)\n","/tmp/ipykernel_34/4092959309.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  hing_y = torch.tensor(hing_y, dtype=torch.long).to(device)\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, en_vocab_size, hing_vocab_size, hidden_size):\n","        super(Seq2Seq, self).__init__()\n","        self.embedding = nn.Embedding(en_vocab_size, 300)\n","        self.encoder = nn.LSTM(300, hidden_size)\n","        self.decoder = nn.LSTM(hidden_size, hidden_size)\n","        self.linear = nn.Linear(hidden_size, hing_vocab_size)\n","        self.dropout = nn.Dropout(0.4)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        encoded, (hidden, cell) = self.encoder(embedded)\n","        decoded = self.dropout(encoded)\n","        decoded, _ = self.decoder(decoded, (hidden, cell))\n","        output = self.linear(decoded)\n","        return output\n","\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","hidden_size = 256\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = Seq2Seq(en_vocab_size, hing_vocab_size, hidden_size).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","en_x = torch.tensor(en_x, dtype=torch.long).to(device)\n","hing_y = torch.tensor(hing_y, dtype=torch.long).to(device)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T22:00:22.755505Z","iopub.status.busy":"2024-05-07T22:00:22.754859Z","iopub.status.idle":"2024-05-07T22:00:30.354775Z","shell.execute_reply":"2024-05-07T22:00:30.353329Z","shell.execute_reply.started":"2024-05-07T22:00:22.755476Z"},"trusted":true},"outputs":[],"source":["# Train the model\n","num_epochs = 20\n","batch_size = 16\n","validation_split = 0.2\n","\n","accumulation_steps = 4\n","train_losses = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    optimizer.zero_grad()  \n","    for i in range(0, len(en_x), batch_size):\n","        inputs = en_x[i:i+batch_size]\n","        labels = hing_y[i:i+batch_size]\n","\n","        outputs = model(inputs)\n","        outputs = outputs.permute(1, 0, 2)  \n","        outputs = outputs.reshape(-1, hing_vocab_size)  \n","\n","        labels = labels.permute(1, 0)  \n","        flat_labels = labels.reshape(-1)\n","\n","        if outputs.size(0) > flat_labels.size(0):\n","            outputs = outputs[:flat_labels.size(0), :]\n","        elif outputs.size(0) < flat_labels.size(0):\n","            flat_labels = flat_labels[:outputs.size(0)]\n","\n","        loss = criterion(outputs, flat_labels)\n","        (loss / accumulation_steps).backward()  \n","        running_loss += loss.item()\n","\n","        if (i // batch_size + 1) % accumulation_steps == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","    running_loss /= (len(en_x) / batch_size)\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss:.4f}')\n","    train_losses.append(running_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:12:52.725496Z","iopub.status.idle":"2024-05-07T21:12:52.725949Z","shell.execute_reply":"2024-05-07T21:12:52.725720Z","shell.execute_reply.started":"2024-05-07T21:12:52.725702Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["Plot the per-epoch training and validation accuracy:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:12:52.727192Z","iopub.status.idle":"2024-05-07T21:12:52.727691Z","shell.execute_reply":"2024-05-07T21:12:52.727446Z","shell.execute_reply.started":"2024-05-07T21:12:52.727426Z"},"trusted":true},"outputs":[],"source":["# # Train the model\n","# # num_epochs = 20\n","# # batch_size = 16\n","# # validation_split = 0.2\n","\n","# # accumulation_steps = 4\n","# # train_losses = []\n","\n","# model.eval() \n","# for i in range(0, len(en_x)):\n","#     inputs = en_x[i:i+batch_size]\n","#     labels = hing_y[i:i+batch_size]\n","\n","#     outputs = model(inputs)\n","#     outputs = outputs.permute(1, 0, 2)  \n","#     outputs = outputs.reshape(-1, hing_vocab_size)  \n","\n","#     labels = labels.permute(1, 0)  \n","#     flat_labels = labels.reshape(-1)\n","\n","#     if outputs.size(0) > flat_labels.size(0):\n","#         outputs = outputs[:flat_labels.size(0), :]\n","#     elif outputs.size(0) < flat_labels.size(0):\n","#         flat_labels = flat_labels[:outputs.size(0)]\n","\n","#     loss = criterion(outputs, flat_labels)\n","#     (loss / accumulation_steps).backward()  \n","#     running_loss += loss.item()\n","\n","#     if (i // batch_size + 1) % accumulation_steps == 0:\n","#         optimizer.step()\n","#         optimizer.zero_grad()\n","\n","# running_loss /= (len(en_x) / batch_size)\n","# print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss:.4f}')\n","# train_losses.append(running_loss)"]},{"cell_type":"markdown","metadata":{},"source":["## Using model to translate text"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:28:52.484674Z","iopub.status.busy":"2024-05-08T05:28:52.483829Z","iopub.status.idle":"2024-05-08T05:28:55.239060Z","shell.execute_reply":"2024-05-08T05:28:55.238172Z","shell.execute_reply.started":"2024-05-08T05:28:52.484641Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = Seq2Seq(en_vocab_size, hing_vocab_size, hidden_size = 256).to(device)\n","model.load_state_dict(torch.load('/kaggle/input/lstmmodel/model.pth'))\n","# torch.load('/kaggle/input/lstmmodel/model.pth')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:28:57.773464Z","iopub.status.busy":"2024-05-08T05:28:57.773110Z","iopub.status.idle":"2024-05-08T05:29:02.070550Z","shell.execute_reply":"2024-05-08T05:29:02.069687Z","shell.execute_reply.started":"2024-05-08T05:28:57.773436Z"},"trusted":true},"outputs":[],"source":["def translate_text_pytorch(text, model, en_tokenizer, hing_tokenizer, en_max_len, device):\n","    # Tokenizing the input text\n","    sequence = en_tokenizer.texts_to_sequences([text])\n","    padded_sequence = torch.tensor(sequence, dtype=torch.long, device=device)  # Directly create tensor on device\n","    \n","    padded_sequence = padded_sequence.to(device).long()\n","    \n","    if len(padded_sequence.shape) == 1:\n","        padded_sequence = padded_sequence.unsqueeze(0)\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        prediction = model(padded_sequence).squeeze(0)\n","    \n","    prediction = prediction.cpu().numpy()  # Move prediction to CPU for NumPy operations\n","    indexes = [np.argmax(idx) for idx in prediction]\n","    translated_text = hing_tokenizer.sequences_to_texts([indexes])[0]\n","    \n","    return translated_text\n","\n","\n","df_test = pd.read_csv('/kaggle/input/enhingdataset/test.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","df_test['en'] = df_test['en'].apply(lambda row: clean_text(row, language='en'))\n","df_test['hing'] = df_test['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\n","en_test = df_test['en']\n","hing_test = df_test['hing']\n","\n","\n","texts = list(en_test)\n","translated = []\n","for text in texts:\n","    translated.append(translate_text_pytorch(text, model, en_tokenizer, hing_tokenizer, en_max_len, device))\n","#     print(f'{text} => {translated}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T22:02:33.813327Z","iopub.status.busy":"2024-05-07T22:02:33.812968Z","iopub.status.idle":"2024-05-07T22:02:33.817648Z","shell.execute_reply":"2024-05-07T22:02:33.816670Z","shell.execute_reply.started":"2024-05-07T22:02:33.813299Z"},"trusted":true},"outputs":[],"source":["# for i in range(20) :\n","#     print(f'{translated[i]}')\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T05:32:35.828844Z","iopub.status.busy":"2024-05-08T05:32:35.827945Z","iopub.status.idle":"2024-05-08T05:32:35.836003Z","shell.execute_reply":"2024-05-08T05:32:35.834884Z","shell.execute_reply.started":"2024-05-08T05:32:35.828810Z"},"trusted":true},"outputs":[],"source":["# # Translating \"you are good\"\n","# translated_text = translate_text_pytorch('you are good', model, en_tokenizer, hing_tokenizer, en_max_len, device)\n","# print(translated_text)\n","\n","with open('translated.txt', 'w', encoding='utf-8') as file:\n","    for translate in translated:\n","        file.write(translate + '\\n')"]},{"cell_type":"markdown","metadata":{},"source":["The model isn't that good, as the bleu score for this is around 0.0173 only"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4724085,"sourceId":8018291,"sourceType":"datasetVersion"},{"datasetId":4960879,"sourceId":8349977,"sourceType":"datasetVersion"},{"datasetId":4962930,"sourceId":8352930,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
