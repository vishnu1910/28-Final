{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-08T11:22:08.979226Z","iopub.status.busy":"2024-05-08T11:22:08.978337Z","iopub.status.idle":"2024-05-08T11:22:11.191894Z","shell.execute_reply":"2024-05-08T11:22:11.191027Z","shell.execute_reply.started":"2024-05-08T11:22:08.979192Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv('/kaggle/input/eng-hing/train.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","df = df.sample(frac=1, random_state=42)\n","df = df.reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:11.193899Z","iopub.status.busy":"2024-05-08T11:22:11.193591Z","iopub.status.idle":"2024-05-08T11:22:11.213932Z","shell.execute_reply":"2024-05-08T11:22:11.213007Z","shell.execute_reply.started":"2024-05-08T11:22:11.193860Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>hing</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How to play with other people</td>\n","      <td>other people के साथ कैसे खेलें</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>One Hundred Years of Solitude</td>\n","      <td>Solitude के सौ Years</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Take this route with the help of a local person</td>\n","      <td>किसी स्थानीय व्यक्ति की help से इसी route को प...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>for the People of the Right Hand</td>\n","      <td>दाहिने हाथ में नामए आमाल लेने People के वास्ते है</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>And those who are fearful of their Lord s doom</td>\n","      <td>और जो लोग अपने Lord के doom से fearful हैं</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>248324</th>\n","      <td>to lasting friendship between India and Mozamb...</td>\n","      <td>India और मोजाम्बिक के बीच स्थायी मैत्री की काम...</td>\n","    </tr>\n","    <tr>\n","      <th>248325</th>\n","      <td>Google Drive cannot be reached at this time</td>\n","      <td>इस time Google Drive तक नहीं पहुंचा जा सकता</td>\n","    </tr>\n","    <tr>\n","      <th>248326</th>\n","      <td>Here this is my new sweetheart</td>\n","      <td>यहाँ यह मेरी new sweetheart है</td>\n","    </tr>\n","    <tr>\n","      <th>248327</th>\n","      <td>Let them remember that nature is the finest ph...</td>\n","      <td>उन्हें यह याद रखना चाहिये कि finest physician ...</td>\n","    </tr>\n","    <tr>\n","      <th>248328</th>\n","      <td>And so these findings I think are really very ...</td>\n","      <td>और इसलिए मैं सोचता हूँ की यह findings परिणाम ब...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>248329 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                       en  \\\n","0                           How to play with other people   \n","1                           One Hundred Years of Solitude   \n","2         Take this route with the help of a local person   \n","3                        for the People of the Right Hand   \n","4          And those who are fearful of their Lord s doom   \n","...                                                   ...   \n","248324  to lasting friendship between India and Mozamb...   \n","248325        Google Drive cannot be reached at this time   \n","248326                     Here this is my new sweetheart   \n","248327  Let them remember that nature is the finest ph...   \n","248328  And so these findings I think are really very ...   \n","\n","                                                     hing  \n","0                          other people के साथ कैसे खेलें  \n","1                                    Solitude के सौ Years  \n","2       किसी स्थानीय व्यक्ति की help से इसी route को प...  \n","3       दाहिने हाथ में नामए आमाल लेने People के वास्ते है  \n","4              और जो लोग अपने Lord के doom से fearful हैं  \n","...                                                   ...  \n","248324  India और मोजाम्बिक के बीच स्थायी मैत्री की काम...  \n","248325        इस time Google Drive तक नहीं पहुंचा जा सकता  \n","248326                     यहाँ यह मेरी new sweetheart है  \n","248327  उन्हें यह याद रखना चाहिये कि finest physician ...  \n","248328  और इसलिए मैं सोचता हूँ की यह findings परिणाम ब...  \n","\n","[248329 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:11.215820Z","iopub.status.busy":"2024-05-08T11:22:11.215408Z","iopub.status.idle":"2024-05-08T11:22:13.397340Z","shell.execute_reply":"2024-05-08T11:22:13.396260Z","shell.execute_reply.started":"2024-05-08T11:22:11.215788Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>hing</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How to play with other people</td>\n","      <td>[start] other people के साथ कैसे खेलें [end]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>One Hundred Years of Solitude</td>\n","      <td>[start] Solitude के सौ Years [end]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Take this route with the help of a local person</td>\n","      <td>[start] किसी स्थानीय व्यक्ति की help से इसी ro...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>for the People of the Right Hand</td>\n","      <td>[start] दाहिने हाथ में नामए आमाल लेने People क...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>And those who are fearful of their Lord s doom</td>\n","      <td>[start] और जो लोग अपने Lord के doom से fearful...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>248324</th>\n","      <td>to lasting friendship between India and Mozamb...</td>\n","      <td>[start] India और मोजाम्बिक के बीच स्थायी मैत्र...</td>\n","    </tr>\n","    <tr>\n","      <th>248325</th>\n","      <td>Google Drive cannot be reached at this time</td>\n","      <td>[start] इस time Google Drive तक नहीं पहुंचा जा...</td>\n","    </tr>\n","    <tr>\n","      <th>248326</th>\n","      <td>Here this is my new sweetheart</td>\n","      <td>[start] यहाँ यह मेरी new sweetheart है [end]</td>\n","    </tr>\n","    <tr>\n","      <th>248327</th>\n","      <td>Let them remember that nature is the finest ph...</td>\n","      <td>[start] उन्हें यह याद रखना चाहिये कि finest ph...</td>\n","    </tr>\n","    <tr>\n","      <th>248328</th>\n","      <td>And so these findings I think are really very ...</td>\n","      <td>[start] और इसलिए मैं सोचता हूँ की यह findings ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>248329 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                       en  \\\n","0                           How to play with other people   \n","1                           One Hundred Years of Solitude   \n","2         Take this route with the help of a local person   \n","3                        for the People of the Right Hand   \n","4          And those who are fearful of their Lord s doom   \n","...                                                   ...   \n","248324  to lasting friendship between India and Mozamb...   \n","248325        Google Drive cannot be reached at this time   \n","248326                     Here this is my new sweetheart   \n","248327  Let them remember that nature is the finest ph...   \n","248328  And so these findings I think are really very ...   \n","\n","                                                     hing  \n","0            [start] other people के साथ कैसे खेलें [end]  \n","1                      [start] Solitude के सौ Years [end]  \n","2       [start] किसी स्थानीय व्यक्ति की help से इसी ro...  \n","3       [start] दाहिने हाथ में नामए आमाल लेने People क...  \n","4       [start] और जो लोग अपने Lord के doom से fearful...  \n","...                                                   ...  \n","248324  [start] India और मोजाम्बिक के बीच स्थायी मैत्र...  \n","248325  [start] इस time Google Drive तक नहीं पहुंचा जा...  \n","248326       [start] यहाँ यह मेरी new sweetheart है [end]  \n","248327  [start] उन्हें यह याद रखना चाहिये कि finest ph...  \n","248328  [start] और इसलिए मैं सोचता हूँ की यह findings ...  \n","\n","[248329 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import re\n","from unicodedata import normalize\n","\n","\n","def clean_text(text, language='en'):\n","    if isinstance(text, float) and np.isnan(text):  # Check if text is NaN\n","        return ''  # Return empty string for NaN values\n","    text = normalize('NFD', text)\n","    if language == 'en':\n","        text = re.sub('[^A-Za-z .\\']+', '', text)\n","    elif language == 'hing': \n","        text = re.sub('[^\\u0900-\\u097F A-Za-z .\\']+', '', text)\n","    return text\n","\n","def clean_and_prepare_text(text, language='hing'):\n","    text = '[start] ' + clean_text(text, language=language) + ' [end]'\n","    return text\n","\n","# Apply it to your dataframe like this:\n","df['en'] = df['en'].apply(lambda row: clean_text(row, language='en'))\n","df['hing'] = df['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\n","df\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:13.399831Z","iopub.status.busy":"2024-05-08T11:22:13.399521Z","iopub.status.idle":"2024-05-08T11:22:13.873588Z","shell.execute_reply":"2024-05-08T11:22:13.872568Z","shell.execute_reply.started":"2024-05-08T11:22:13.399805Z"},"trusted":true},"outputs":[],"source":["en = df['en']\n","hing = df['hing']\n","\n","en_max_len = max(len(line.split()) for line in en)\n","hing_max_len = max(len(line.split()) for line in hing)\n","sequence_len = max(en_max_len, hing_max_len)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:13.875312Z","iopub.status.busy":"2024-05-08T11:22:13.874981Z","iopub.status.idle":"2024-05-08T11:22:46.963295Z","shell.execute_reply":"2024-05-08T11:22:46.962450Z","shell.execute_reply.started":"2024-05-08T11:22:13.875286Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-08 11:22:15.618534: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-08 11:22:15.618656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-08 11:22:15.754143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# from tensorflow.keras.preprocessing.text import Tokenizer\n","# from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# en_tokenizer = Tokenizer()\n","# en_tokenizer.fit_on_texts(en)\n","# en_sequences = en_tokenizer.texts_to_sequences(en)\n","# en_x = pad_sequences(en_sequences, maxlen=sequence_len, padding='post')\n","\n","# hing_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n')\n","# hing_tokenizer.fit_on_texts(hing)\n","# hing_sequences = fr_tokenizer.texts_to_sequences(hing)\n","# hing_y = pad_sequences(hing_sequences, maxlen=sequence_len + 1, padding='post')\n","\n","from collections import defaultdict\n","import torch\n","class Tokenizer:\n","    def __init__(self):\n","        self.word_index = {}\n","        self.index_word = {}\n","    \n","    def fit_on_texts(self, texts):\n","        word_freq = defaultdict(int)\n","        for text in texts:\n","            for word in text.split():\n","                word_freq[word] += 1\n","        self.word_index = {word: i+1 for i, (word, freq) in enumerate(sorted(word_freq.items(), key=lambda x: x[1], reverse=True))}\n","        self.index_word = {i: word for word, i in self.word_index.items()}\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            seq = [self.word_index.get(word, 0) for word in text.split()]\n","            sequences.append(seq)\n","        return sequences\n","    \n","    def sequences_to_texts(self, sequences):\n","        texts = []\n","        for sequence in sequences:\n","            words = [self.index_word.get(idx, \"<unk>\") for idx in sequence if idx > 0]  # Skip padding\n","            text = \" \".join(words)\n","            texts.append(text)\n","        return texts\n","\n","def pad_sequences(sequences, maxlen, padding='post'):\n","    max_seq_len = max(len(seq) for seq in sequences)\n","    padded_seqs = torch.zeros((len(sequences), maxlen), dtype=torch.long)\n","    for i, seq in enumerate(sequences):\n","        if padding == 'post':\n","            padded_seqs[i, :len(seq)] = torch.tensor(seq[:maxlen], dtype=torch.long)\n","        else:  \n","            padded_seqs[i, -len(seq):] = torch.tensor(seq[-maxlen:], dtype=torch.long)\n","    return padded_seqs\n","\n","en_tokenizer = Tokenizer()\n","en_tokenizer.fit_on_texts(en)\n","en_sequences = en_tokenizer.texts_to_sequences(en)\n","en_x = pad_sequences(en_sequences, maxlen=en_max_len, padding='post')\n","\n","hing_tokenizer = Tokenizer()\n","hing_tokenizer.fit_on_texts(hing)\n","hing_sequences = hing_tokenizer.texts_to_sequences(hing)\n","hing_y = pad_sequences(hing_sequences, maxlen=hing_max_len, padding='post')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:46.965072Z","iopub.status.busy":"2024-05-08T11:22:46.964493Z","iopub.status.idle":"2024-05-08T11:22:46.970660Z","shell.execute_reply":"2024-05-08T11:22:46.969694Z","shell.execute_reply.started":"2024-05-08T11:22:46.965025Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary size (English): 63518\n","Vocabulary size (Hinglish): 101275\n"]}],"source":["en_vocab_size = len(en_tokenizer.word_index) + 1\n","hing_vocab_size = len(hing_tokenizer.word_index) + 1\n","\n","print(f'Vocabulary size (English): {en_vocab_size}')\n","print(f'Vocabulary size (Hinglish): {hing_vocab_size}')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:46.972354Z","iopub.status.busy":"2024-05-08T11:22:46.972018Z","iopub.status.idle":"2024-05-08T11:22:46.989427Z","shell.execute_reply":"2024-05-08T11:22:46.988366Z","shell.execute_reply.started":"2024-05-08T11:22:46.972325Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["array([[    1,   105,    89, ...,     0,     0,     0],\n","       [    1, 15225,     5, ...,     0,     0,     0],\n","       [    1,    38,  2384, ...,     0,     0,     0],\n","       ...,\n","       [    1,   123,    18, ...,     0,     0,     0],\n","       [    1,   109,    18, ...,     0,     0,     0],\n","       [    1,     8,   277, ...,     0,     0,     0]], dtype=int32)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["hing_y[:,:-1]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:46.991048Z","iopub.status.busy":"2024-05-08T11:22:46.990712Z","iopub.status.idle":"2024-05-08T11:22:46.997773Z","shell.execute_reply":"2024-05-08T11:22:46.996809Z","shell.execute_reply.started":"2024-05-08T11:22:46.991014Z"},"trusted":true},"outputs":[],"source":["inputs = { 'encoder_input': en_x, 'decoder_input': hing_y[:, :-1] }\n","outputs = hing_y[:, 1:]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:46.999378Z","iopub.status.busy":"2024-05-08T11:22:46.998963Z","iopub.status.idle":"2024-05-08T11:22:49.741212Z","shell.execute_reply":"2024-05-08T11:22:49.740199Z","shell.execute_reply.started":"2024-05-08T11:22:46.999315Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_3\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n","┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n","│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ token_and_position_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,289,792</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)       │                              │                   │                           \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ transformer_encoder               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">395,776</span> │ token_and_position_embeddi\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)              │                              │                   │                           \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101275</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,642,715</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n","│                                   │                              │                   │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n","│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ token_and_position_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m16,289,792\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n","│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)       │                              │                   │                           \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ transformer_encoder               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m395,776\u001b[0m │ token_and_position_embeddi\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)              │                              │                   │                           \n","├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n","│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101275\u001b[0m)         │        \u001b[38;5;34m52,642,715\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n","│                                   │                              │                   │ transformer_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n","└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,328,283</span> (264.47 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,328,283\u001b[0m (264.47 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,328,283</span> (264.47 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,328,283\u001b[0m (264.47 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from keras_nlp.layers import TokenAndPositionEmbedding, TransformerEncoder\n","from keras_nlp.layers import TransformerDecoder\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","num_heads = 8\n","embed_dim = 256\n","\n","encoder_input = Input(shape=(None,), dtype='int64', name='encoder_input')\n","x = TokenAndPositionEmbedding(en_vocab_size, sequence_len, embed_dim)(encoder_input)\n","encoder_output = TransformerEncoder(embed_dim, num_heads)(x)\n","encoded_seq_input = Input(shape=(None, embed_dim))\n","\n","decoder_input = Input(shape=(None,), dtype='int64', name='decoder_input')\n","x = TokenAndPositionEmbedding(hing_vocab_size, sequence_len, embed_dim, mask_zero=True)(decoder_input)\n","x = TransformerDecoder(embed_dim, num_heads)(x, encoded_seq_input)\n","x = Dropout(0.4)(x)\n","\n","decoder_output = Dense(hing_vocab_size, activation='softmax')(x)\n","decoder = Model([decoder_input, encoded_seq_input], decoder_output)\n","decoder_output = decoder([decoder_input, encoder_output])\n","\n","model = Model([encoder_input, decoder_input], decoder_output)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary(line_length=120)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T11:22:49.744831Z","iopub.status.busy":"2024-05-08T11:22:49.744529Z","iopub.status.idle":"2024-05-08T14:23:28.077496Z","shell.execute_reply":"2024-05-08T14:23:28.075292Z","shell.execute_reply.started":"2024-05-08T11:22:49.744808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m   1/6209\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30:04:56\u001b[0m 17s/step - accuracy: 5.4825e-04 - loss: 11.5222"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1715167387.403329      81 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","W0000 00:00:1715167387.433179      81 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0273 - loss: 5.9769"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1715168210.529096      83 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1715168212.397020      83 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 145ms/step - accuracy: 0.0272 - loss: 5.9768 - val_accuracy: 0.0280 - val_loss: 5.1709\n","Epoch 2/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 143ms/step - accuracy: 0.0293 - loss: 4.9860 - val_accuracy: 0.0313 - val_loss: 4.8307\n","Epoch 3/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 144ms/step - accuracy: 0.0411 - loss: 4.4429 - val_accuracy: 0.0446 - val_loss: 4.6143\n","Epoch 4/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 143ms/step - accuracy: 0.0558 - loss: 3.9520 - val_accuracy: 0.0360 - val_loss: 4.4895\n","Epoch 5/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 143ms/step - accuracy: 0.0517 - loss: 3.5163 - val_accuracy: 0.0377 - val_loss: 4.3568\n","Epoch 6/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 143ms/step - accuracy: 0.0717 - loss: 3.1540 - val_accuracy: 0.0523 - val_loss: 4.2974\n","Epoch 7/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 144ms/step - accuracy: 0.0631 - loss: 2.8613 - val_accuracy: 0.0492 - val_loss: 4.2782\n","Epoch 8/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 144ms/step - accuracy: 0.0763 - loss: 2.6259 - val_accuracy: 0.0619 - val_loss: 4.2821\n","Epoch 9/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 144ms/step - accuracy: 0.0815 - loss: 2.4298 - val_accuracy: 0.0981 - val_loss: 4.2539\n","Epoch 10/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 144ms/step - accuracy: 0.0944 - loss: 2.2637 - val_accuracy: 0.2678 - val_loss: 4.2884\n","Epoch 11/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 143ms/step - accuracy: 0.1614 - loss: 2.1199 - val_accuracy: 0.2062 - val_loss: 4.3370\n","Epoch 12/50\n","\u001b[1m6209/6209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 144ms/step - accuracy: 0.2549 - loss: 1.9976 - val_accuracy: 0.1168 - val_loss: 4.3545\n","Epoch 13/50\n","\u001b[1m 655/6209\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:14\u001b[0m 132ms/step - accuracy: 0.1373 - loss: 1.9252"]},{"name":"stderr","output_type":"stream","text":["\n","KeyboardInterrupt\n","\n"]}],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","\n","\n","callback = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n","hist = model.fit(inputs, outputs, epochs=50, validation_split=0.2, callbacks=[callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow.keras.backend as K\n","from tensorflow.keras.models import save_model\n","\n","# Clear the Keras session and reset the graph\n","K.clear_session()\n","\n","# Save the model\n","save_model(model, '/kaggle/working/model.h5')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:03:10.453258Z","iopub.status.busy":"2024-05-08T15:03:10.452808Z","iopub.status.idle":"2024-05-08T15:09:35.110958Z","shell.execute_reply":"2024-05-08T15:09:35.109628Z","shell.execute_reply.started":"2024-05-08T15:03:10.453227Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"," 40%|███▉      | 799/2000 [06:24<09:37,  2.08it/s]\n"]},{"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 113 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m translated \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(texts):\n\u001b[0;32m---> 45\u001b[0m     translated\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhing_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhing_index_lookup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_len\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[23], line 14\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(text, model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len)\u001b[0m\n\u001b[1;32m     10\u001b[0m padded_target_sequence \u001b[38;5;241m=\u001b[39m pad_sequences(target_sequence, maxlen\u001b[38;5;241m=\u001b[39msequence_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model([padded_input_sequence, padded_target_sequence])\n\u001b[0;32m---> 14\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m token \u001b[38;5;241m=\u001b[39m fr_index_lookup[idx]\n\u001b[1;32m     16\u001b[0m decoded_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m token\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 113 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"]}],"source":["from tqdm import tqdm\n","\n","def translate_text(text, model, en_tokenizer, fr_tokenizer, fr_index_lookup, sequence_len):\n","    input_sequence = en_tokenizer.texts_to_sequences([text])\n","    padded_input_sequence = pad_sequences(input_sequence, maxlen=sequence_len, padding='post')\n","    decoded_text = '[start]'\n","\n","    for i in range(sequence_len):\n","        target_sequence = fr_tokenizer.texts_to_sequences([decoded_text])\n","        padded_target_sequence = pad_sequences(target_sequence, maxlen=sequence_len, padding='post')[:, :-1]\n","        \n","        prediction = model([padded_input_sequence, padded_target_sequence])\n","\n","        idx = np.argmax(prediction[0, i, :]) - 1\n","        token = fr_index_lookup[idx]\n","        decoded_text += ' ' + token\n","\n","        if token == '[end]':\n","            break\n","    \n","    return decoded_text[8:-6] \n","hing_vocab = hing_tokenizer.word_index\n","hing_index_lookup = dict(zip(range(len(hing_vocab)), hing_vocab))\n","\n","df_test = pd.read_csv('/kaggle/input/eng-hing/test.txt', names=['en', 'hing'], usecols=['en', 'hing'], sep='\\t')\n","df_test['en'] = df_test['en'].apply(lambda row: clean_text(row, language='en'))\n","df_test['hing'] = df_test['hing'].apply(lambda row: clean_and_prepare_text(row, language='hing'))\n","en_test = df_test['en']\n","hing_test = df_test['hing']\n","\n","\n","texts = en_test[:].values\n","translated = []\n","\n","for text in tqdm(texts):\n","    translated.append(translate_text(text, model, en_tokenizer, hing_tokenizer, hing_index_lookup, sequence_len))"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-08T15:12:39.711634Z","iopub.status.busy":"2024-05-08T15:12:39.710846Z","iopub.status.idle":"2024-05-08T15:12:39.718549Z","shell.execute_reply":"2024-05-08T15:12:39.717497Z","shell.execute_reply.started":"2024-05-08T15:12:39.711602Z"},"trusted":true},"outputs":[],"source":["with open('translated.txt', 'w', encoding='utf-8') as file:\n","    for translate in translated:\n","        file.write(translate + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4819712,"sourceId":8149573,"sourceType":"datasetVersion"},{"datasetId":4956174,"sourceId":8343872,"sourceType":"datasetVersion"},{"datasetId":4960934,"sourceId":8350042,"sourceType":"datasetVersion"},{"datasetId":4963298,"sourceId":8353406,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
